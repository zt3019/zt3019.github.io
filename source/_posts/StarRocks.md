---
title: StarRocks
date: 2024-01-03 10:48:38
tags: 
- 大数据
categories:
- 大数据
index_img: https://tse4-mm.cn.bing.net/th/id/OIP-C.WB-odJpxpYgl5OkJXUXU-gHaHa?rs=1&pid=ImgDetMain
banner_img: https://tse4-mm.cn.bing.net/th/id/OIP-C.WB-odJpxpYgl5OkJXUXU-gHaHa?rs=1&pid=ImgDetMain
---

# StarRocks

## 基础介绍

* 社区还是很活跃的，贴一下官方文档：[StarRocks官方文档](https://docs.starrocks.io/zh/docs/introduction/StarRocks_intro/)
* 官方描述：StarRocks 是一款高性能分析型数据仓库，使用向量化、MPP 架构、CBO、智能物化视图、可实时更新的列式存储引擎等技术实现多维、实时、高并发的数据分析。StarRocks 既支持从各类实时和离线的数据源高效导入数据，也支持直接分析数据湖上各种格式的数据。StarRocks 兼容 MySQL 协议，可使用 MySQL 客户端和常用 BI 工具对接。同时 StarRocks 具备水平扩展，高可用、高可靠、易运维等特性。广泛应用于实时数仓、OLAP 报表、数据湖分析等场景。
* StarRocks 是新一代极速全场景 MPP (Massively Parallel Processing) 数据库。StarRocks 的愿景是能够让用户的数据分析变得更加简单和敏捷。
* StarRocks 架构简洁，采用了全面向量化引擎，并配备全新设计的 CBO (Cost Based Optimizer) 优化器，查询速度（尤其是多表关联查询）远超同类产品。

### 适用场景

* StarRocks 可以满足企业级用户的多种分析需求，包括 OLAP (Online Analytical Processing) 多维分析、定制报表、实时数据分析和 Ad-hoc 数据分析等。
* OLAP多维分析：利用 StarRocks 的 MPP 框架和向量化执行引擎，用户可以灵活的选择雪花模型，星型模型，宽表模型或者预聚合模型。适用于灵活配置的多维分析报表，业务场景包括：
  - 用户行为分析
  - 用户画像、标签分析、圈人
  - 自助式报表平台
  - 系统监控分析
* 实时数据仓库：StarRocks 设计和实现了 Primary-Key 模型，能够实时更新数据并极速查询，可以秒级同步 TP (Transaction Processing) 数据库的变化，构建实时数仓，业务场景包括：
  - 电商大促数据分析
  - 物流行业的运单分析
  - 金融行业绩效分析、指标计算
* 高并发查询：StarRocks 通过良好的数据分布特性，灵活的索引以及物化视图等特性，可以解决面向用户侧的分析场景，业务场景包括
  - 广告主报表分析
  - SaaS 行业面向用户分析报表
* 统一分析：
  - 通过使用一套系统解决多维分析、高并发查询、预计算、实时分析查询等场景，降低系统复杂度和多技术栈开发与维护成本。
  - 使用 StarRocks 统一管理数据湖和数据仓库，将高并发和实时性要求很高的业务放在 StarRocks 中分析，也可以使用 External Catalog 和外部表进行数据湖上的分析。

### 系统架构

* 架构简洁，核心只有FE(Frontend),BE(Backend)或CN(Compute Node)两类进程，方便部署维护，可水平扩展，有副本机制，确保系统无单点。SR支持Mysql协议接口，支持SQL标准语法。

* [![pFJGuQg.png](https://s11.ax1x.com/2024/02/18/pFJGuQg.png)](https://imgse.com/i/pFJGuQg)

* FE 节点负责元数据管理、客户端连接管理、查询计划和查询调度。每个 FE 在其内存中存储和维护完整的元数据副本，确保每个 FE 都能提供无差别的服务。

* CN 节点在存算分离或存算一体集群中负责执行查询。

* BE 节点在存算一体集群中负责数据存储和执行查询。

* 从存算一体(shared-nothing)进化到存算分离(shared-data)
  - 3.0 版本之前使用存算一体架构，BE 同时负责数据存储和计算，数据访问和分析都在本地进行，提供极速的查询分析体验。
  - 3.0 版本开始引入存算分离架构，数据存储功能从原来的 BE 中抽离，BE 节点升级为无状态的 CN 节点。数据可持久存储在远端对象存储或 HDFS 上，CN 本地磁盘只用于缓存热数据来加速查询。存算分离架构下支持动态增删计算节点，实现秒级的扩缩容能力。
  - 存算分离支持的存储系统：兼容 AWS S3 协议的对象存储系统；Azure Blob Storage；传统数据中心部署的 HDFS
  
* 解释一下catlog的作用，以Flink Catalog为例：

  - Catalog 提供了一个统一的 API 来管理元数据，并使其可以从表 API 和 SQL 查询语句中来访问。

  - Catalog 使用户能够引用他们数据系统中的现有元数据，并自动将它们映射到 Flink 的相应元数据。
  - 例如，Flink 可以将 JDBC 表自动映射到 Flink 表，用户不必在 Flink 中手动重写 DDL。Catalog 大大简化了用户现有系统开始使用 Flink 所需的步骤，并增强了用户体验。

* schema的作用：schema是对一个数据库的结构描述。在一个关系型数据库里面，schema定义了表、每个表的字段，还有表和字段之间的关系。

* 缓存：为了提升存算分离架构的查询性能，SR构建了分级的数据缓存体系，将最热的数据缓存在内存中，距离计算最近；次热数据则缓存在本地磁盘，冷数据位于对象存储，数据根据访问频率在三级存储中自由流动。

  - 具体细节：

  - StarRocks 存算分离的统一缓存允许用户在建表时决定是否开启缓存。如果开启，数据写入时会同步写入本地磁盘以及后端对象存储，查询时，CN 节点会优先从本地磁盘读取数据，如果未命中，再从后端对象存储读取原始数据并同时缓存在本地磁盘。

    同时，针对未被缓存的冷数据，StarRocks 也进行了针对性优化，可根据应用访问模式，利用数据预读技术、并行扫描技术等手段，减少对于后端对象存储的访问频次，提升查询性能。

### 产品特性

* MPP分布式执行框架
  - StarRocks 采用 MPP (Massively Parallel Processing) 分布式执行框架。在MPP执行框架中，**一条查询请求会被拆分成多个物理计算单元，在多机并行执行**。每个执行节点拥有独享的资源（CPU、内存）。
  - 不同逻辑执行单元可以由不同数目的物理执行单元来具体执行，以提高资源使用率，提升查询速度。
  - **在 MPP 框架中，数据会被 Shuffle 到多个节点，并且由多个节点来完成最后的汇总计算。**
* 全面向量化执行引擎
  - StarRocks 通过实现全面向量化引擎，充分发挥了 CPU 的处理能力。全面向量化引擎按照列式的方式组织和处理数据。**StarRocks 的数据存储、内存中数据的组织方式，以及 SQL 算子的计算方式，都是列式实现的**。按列的数据组织也会更加充分的利用 CPU 的 Cache，按列计算会有更少的虚函数调用以及更少的分支判断从而获得更加充分的 CPU 指令流水。
* 存储计算分离
  - 存算分离，存储与计算解耦，独立扩缩容
* CBO优化器
  - 厉害的查询优化器，选择出相对最优的查询计划
* 可实时更新的列式存储引擎
  - **实现列式存储，数据以列的方式存储，相同类型的数据连续存放**
  - 提高压缩比，降低I/O式的总量，提升查询性能
  - StarRocks 能够支持秒级的导入延迟，提供准实时的服务能力。StarRocks 的存储引擎在数据导入时能够保证每一次操作的 ACID。一个批次的导入数据生效是原子性的，要么全部导入成功，要么全部失败
* 智能物化视图
  - **SR物化视图可以根据原始表更新数据，只要原始表发生变化，物化视图会同步更新，不需要额外的维护操作就可以保证物化视图能够维持与原表一致**
  - 物化视图的选择也是自动进行的。StarRocks 在进行查询规划时，如果有合适的物化视图能够加速查询，StarRocks 自动进行查询改写(query rewrite)，将查询自动定位到最适合的物化视图上进行查询加速。
* 数据湖分析
  - StarRocks 不仅能高效的分析本地存储的数据，也**可以作为计算引擎直接分析数据湖中的数据。**
  - 利用SR的提供的 External Catalog，轻松查询存储在Apache Hive、Apache Iceberg、Apache Hudi、Delta Lake 等数据湖上的数据
  - **在数据湖分析场景中，StarRocks 主要负责数据的计算分析**，而数据湖则主要负责数据的存储、组织和维护。使用数据湖的优势在于可以使用开放的存储格式和灵活多变的 schema 定义方式，可以让 BI/AI/Adhoc/报表等业务有统一的 single source of truth。

## 表设计

* SR使用Internal Catlog来管理内部数据，使用 External Catalog 来连接数据湖中的数据。存储在SR中的数据都包含在Internal Catlog下，Internal Catalog 可以包含一个或多个数据库。数据库用于存储、管理和操作 StarRocks 中的数据，可用于管理多种对象，包括表、物化视图、视图等。StarRocks 采用权限系统来管理数据访问权限，定义了用户对哪些对象可以执行哪些操作，提高数据安全性。

* Catalog 分为 Internal catalog 和 External catalog。**Internal catalog 是内部数据目录，用于管理导入至 StarRocks 中的数据以及内部的物化视图等。**每个集群都有且只有一个名为 default_catalog 的 Internal catalog，包含一个或多个数据库。StarRocks 作为数据仓库存储数据，能够显著提高查询性能，尤其应对大规模数据的复杂查询分析。

  External catalog 是外部数据目录，用于连接数据湖中的数据。您可以将 StarRocks 作为查询引擎，直接查询湖上数据，无需导入数据至 StarRocks。

* StarRocks 中的表分为两类：内部表和外部表。

* 内部表归属于 Internal catalog 的数据库，数据保存在 StarRocks 中。内部表由行和列构成，每一行数据是一条记录。

  - 在 StarRocks 中，根据约束的类型将内部表分四种，分别是主键表、明细表、聚合表和更新表，适用于存储和查询多种业务场景中的数据，比如原始日志、实时数据、以及汇总数据。
  - **内部表采用分区+分桶的两级数据分布策略，实现数据均匀分布。并且分桶以多副本形式均匀分布至 BE 节点，保证数据高可用。**

* 外部表是 External catalog 中的表，实际数据存在外部数据源中，StarRocks 只保存表对应的元数据，您可以通过外部表查询外部数据。

#### 物化视图

* **物化视图是特殊的物理表，能够存储基于基表的预计算结果。**当您对基表执行复杂查询时，StarRocks可以自动复用物化视图中的预计算结果，实现查询透明加速，湖仓加速和数据建模等业务需求。
* 视图（也叫逻辑视图）是虚拟表，不存储数据，其中所展示的数据来自于基表生成的查询结果。每次在查询中引用某个视图时，都会运行定义该视图的查询。
* SR有权限系统，权限决定了哪些用户可以对哪些特定对象执行哪些特定的操作。SR采用两种权限模型：**基于用户标识的访问控制和基于角色的访问控制**。您可以将权限赋予给角色然后通过角色传递权限给用户，或直接赋予权限给用户标识。
* 存算分离架构，数据存储功能从原来的BE中抽离，数据可持久存储在更为可靠廉价的远端对象存储（如S3（AWS S3 全名是 Simple Storage Service，简便的存储服务。亚马逊的云存储业务））或HDFS上，本地磁盘只用于缓存热数据来加速查询

### 表概览

* 表是数据存储单元。理解 StarRocks 中的表结构，以及如何设计合理的表结构，有利于优化数据组织，提高查询效率。相比于传统的数据库，StarRocks 会以列的方式存储 JSON、ARRAY 等复杂的半结构化数据，保证高效查询。

#### 表类型

* SR提供四种类型的表，包括明细表，主键表，聚合表和更新表，使用于存储多种业务数据。
  - 明细表简单易用，表中数据不具有任何约束，相同的数据行可以重复存在。**适用于存储不需要约束和预聚合的原始数据。**
  - 主键表能力强大，具有唯一性非空约束。**该表能够支撑实时更新，部分列更新等场景的同时，保证查询性能，使用于实时查询。**
  - **聚合表适用于存储预聚合后的数据，可以降低聚合查询时所需扫描和计算的数据量，极大的提高聚合查询的效率。**
  - 更新表适用于实时更新的业务场景，目前已逐渐被主键表取代。

#### 数据分布

* SR采用分区+分桶的两级数据分布策略，将数据均匀分布各个BE节点。查询时能够有效裁剪数据扫描量，最大限度的利用集群的并发性能。

##### 分区

* **第一层级为分区，表中数据可以根据分区列（通常是时间和日期）分成一个个更小的数据管理单元。**查询时，通过分区裁剪，可以减少扫描的数据量，显著优化查询性能。
* SR提供简单易用的**表达式分区**。还提供更加灵活的分区方式，**Range分区和List分区**。

##### 分桶

* **第二层级为分桶，同一个分区中的数据通过分桶，划分成更小的数据管理单元。**并且分桶以多副本的形式均匀分布在BE节点上，保证数据的高可用。
* SR有两种分桶方式：
  - 哈希分桶：根据数据的分桶键值，将数据划分至分桶。选择查询时经常使用的条件组成分桶键，能够有效的提高查询效率。
  - 随机分桶：随机划分数据至分桶，这种方式更加简单易用。

##### 数据类型

* 支持多种数据类型，和hive差不多

##### 索引

* 索引是一种特殊的数据结构，相当于数据的目录。
* SR提供内置索引，包括前缀索引，Ordinal索引和ZoneMap索引。也支持手动创建索引，提高查询效率，包括Bitmap和Bloom Filter索引。

##### 约束

* 约束用于确保数据的完整性、一致性和准确性。主键表的 Primary Key 列具有唯一非空约束，聚合表的 Aggregate Key 列和更新表的 Unique Key 列具有唯一约束。

### 表类型

#### 基础信息

* 四种表类型：分别是明细表 (Duplicate key table)、聚合表 (Aggregate table)、更新表 (Unique Key table) 和主键表 ( Primary Key table)。

#### 排序键

* 数据导入至使用某个类型的表，会按照建表时指定的一列或多列排序后存储，这部分用于排序的列就称为排序键。排序键通常为查询时过滤条件频繁使用的一个或者多个列，用以加速查询。 明细表中，数据按照排序键 `DUPLICATE KEY` 排序，并且排序键不需要满足唯一性约束。 聚合表中，数据按照排序键 `AGGREGATE KEY` 聚合后排序，并且排序键需要满足唯一性约束。 更新表中，数据按照排序键 `UNIQUE KEY` REPLACE 后排序，并且排序键需要满足唯一性约束。 主键表支持分别定义主键和排序键，主键 `PRIMARY KEY` 需要满足唯一性和非空约束，主键相同的数据进行 REPLACE。排序键是用于排序，由 `ORDER BY` 指定 。
* 在建表语句中，排序键必须定义在其他列之前。
* 在创建表时，您可以将一个或多个列定义为排序键。排序键在建表语句中的出现次序，为数据存储时多重排序的次序。
* 不支持排序键的数据类型为 BITMAP、HLL。
* 前缀索引的长度限制为 36 字节。如果排序键中全部列的值的长度加起来超过 36 字节，则前缀索引仅会保存限制范围内排序键的若干前缀列。
* 如果导入的数据存在重复的主键，则数据导入至不同类型的表时，存储在 StarRocks 时，则会按照如下方式进行处理：
  - 明细表：表中会存在主键重复的数据行，并且与导入的数据是完全对应的。您可以召回所导入的全部历史数据。
  - 聚合表：表中不存在主键重复的数据行，主键满足唯一性约束。导入的数据中主键重复的数据行聚合为一行，即具有相同主键的指标列，会通过聚合函数进行聚合。您只能召回导入的全部历史数据的聚合结果，但是无法召回历史明细数据。
  - 主键表和更新表：表中不存在主键重复的数据行，主键满足唯一性约束。最新导入的数据行，替换掉其他主键重复的数据行。这两种类型的表可以视为聚合表的特殊情况，相当于在聚合表中，为表的指标列指定聚合函数为 REPLACE，REPLACE 函数返回主键相同的一组数据中的最新数据。

#### 明细表

* 明细表是默认创建的表类型。如果在建表时未指定任何key，默认创建的是明细表

* 创建表时，支持定义排序键。如果查询的过滤条件包含排序键，则 StarRocks 能够快速地过滤数据，提高查询效率。**明细表适用于日志数据分析等场景，支持追加新数据，不支持修改历史数据。**

* 建表语句

  ````sqlite
  CREATE TABLE IF NOT EXISTS detail (
      event_time DATETIME NOT NULL COMMENT "datetime of event",
      event_type INT NOT NULL COMMENT "type of event",
      user_id INT COMMENT "id of user",
      device_code INT COMMENT "device code",
      channel INT COMMENT ""
  )
  DUPLICATE KEY(event_time, event_type)
  DISTRIBUTED BY HASH(user_id)
  PROPERTIES (
  "replication_num" = "3"
  );
  ````

  - 排序键的相关说明：

    - 在建表语句中，排序键必须定义在其他列之前。

    - 排序键可以通过 `DUPLICATE KEY` 显式定义。本示例中排序键为 `event_time` 和 `event_type`。

      > 如果未指定，则默认选择表的前三列作为排序键。

    - 明细表中的排序键可以为部分或全部维度列。

  - 建表时，支持为指标列创建 BITMAP、Bloom Filter 等索引。

#### 聚合表

* **建表时，支持定义排序键和指标列，并为指标列指定聚合函数。当多条数据具有相同的排序键时，指标列会进行聚合。**在分析统计和汇总数据时，聚合表能够减少查询时所需要处理的数据，提升查询效率。
* 适用于分析统计和汇总数据
* 原理：**从数据导入至数据查询阶段，聚合表内部同一排序键的数据会多次聚合**，步骤：
  1. 数据导入阶段：数据按批次导入至聚合表时，每一个批次的数据形成一个版本。在一个版本中，同一排序键的数据会进行一次聚合
  2. 后台文件合并阶段（Compaction）：数据分批次多次导入至聚合表中，会生成多个版本的文件，多个版本的文件定期合并成一个大版本文件时，同一排序键的数据会进行一次聚合。
  3. 查询阶段：所有版本中同一排序键的数据进行聚合，然后返回查询结果
* 聚合表中数据进行多次聚合，能够减少查询时所需要处理的数据量，进而提升查询的效率

* 创建表

  ````sqlite
  /*
  例如需要分析某一段时间内，来自不同城市的用户，访问不同网页的总次数。则可以将网页地址 site_id、日期 date 和城市代码 city_code 作为排序键，将访问次数 pv 作为指标列，并为指标列 pv 指定聚合函数为 SUM。
  */
  CREATE TABLE IF NOT EXISTS example_db.aggregate_tbl (
      site_id LARGEINT NOT NULL COMMENT "id of site",
      date DATE NOT NULL COMMENT "time of event",
      city_code VARCHAR(20) COMMENT "city_code of user",
      pv BIGINT SUM DEFAULT "0" COMMENT "total page views"
  )
  AGGREGATE KEY(site_id, date, city_code)
  DISTRIBUTED BY HASH(site_id)
  PROPERTIES (
  "replication_num" = "3"
  );
  ````

* 建表时必须使用 `DISTRIBUTED BY HASH` 子句指定分桶键。分桶键的更多说明，请参见[分桶](https://docs.starrocks.io/zh/docs/table_design/Data_distribution/#分桶)。

* 自 2.5.7 版本起，StarRocks 支持在建表和新增分区时自动设置分桶数量 (BUCKETS)，您无需手动设置分桶数量。更多信息，请参见 [设置分桶数量](https://docs.starrocks.io/zh/docs/table_design/Data_distribution/#设置分桶数量)。

* 排序键的相关说明：

  - 在建表语句中，**排序键必须定义在其他列之前**。

  - 排序键可以通过 `AGGREGATE KEY` 显式定义。

    > - 如果 `AGGREGATE KEY` 未包含全部维度列（除指标列之外的列），则建表会失败。
    > - 如果不通过 `AGGREGATE KEY` 显示定义排序键，则默认除指标列之外的列均为排序键。

  - 排序键必须满足唯一性约束，必须包含全部维度列，并且列的值不会更新。

* 指标列：通过在列名后指定聚合函数，定义该列为指标列。一般为需要汇总统计的数据。

* 聚合函数：指标列使用的聚合函数。聚合表支持的聚合函数，请参见 [CREATE TABLE](https://docs.starrocks.io/zh/docs/sql-reference/sql-statements/data-definition/CREATE_TABLE/)。

* 查询时，排序键在多版聚合之前就能进行过滤，而指标列的过滤在多版本聚合之后。因此建议将频繁使用的过滤字段作为排序键，在聚合前就能过滤数据，从而提升查询性能。

* 建表时，不支持为指标列创建 BITMAP、Bloom Filter 等索引。

#### 更新表

* 建表时，支持定义主键和指标列，查询时返回主键相同的一组数据中的最新数据。相对于明细表，更新表简化了数据导入流程，能够更好地支撑实时和频繁更新的场景。

* 建表

  ````sqlite
  CREATE TABLE IF NOT EXISTS orders (
      create_time DATE NOT NULL COMMENT "create time of an order",
      order_id BIGINT NOT NULL COMMENT "id of an order",
      order_state INT COMMENT "state of an order",
      total_price BIGINT COMMENT "price of an order"
  )
  UNIQUE KEY(create_time, order_id)
  DISTRIBUTED BY HASH(order_id)
  PROPERTIES (
  "replication_num" = "3"
  ); 
  ````

#### 主键表

* 主键表支持分别定义主键和排序键。数据导入至主键表时先按照排序键排序后存储。查询时返回主键相同的一组数据中的最新数据。相对于更新表，主键表在查询时不需要执行聚合操作，并且支持谓词和索引下推，能够在支持**实时和频繁更新**等场景的同时，提供高效查询。
* 适用场景：
  - **实时对接事务型数据至StarRocks。**[通过 Flink-CDC 等工具直接对接 TP 的 Binlog](https://docs.starrocks.io/zh/docs/loading/Flink_cdc_load/)，实时同步增删改的数据至主键表，可以简化数据同步流程，并且相对于 Merge-On-Read 策略的更新表，查询性能能够提升 3~10 倍。
  - **利用部分列更新轻松实现多流JOIN**。在用户画像等分析场景中，一般会采用大宽表方式来提升多维分析的性能，同时简化数据分析师的使用模型。而这种场景中的上游数据，往往可能来自于多个不同业务（比如来自购物消费业务、快递业务、银行业务等）或系统（比如计算用户不同标签属性的机器学习系统），主键表的部分列更新功能就很好地满足这种需求，不同业务直接各自按需更新与业务相关的列即可，并且继续享受主键表的实时同步增删改数据及高效的查询性能。
  - 
