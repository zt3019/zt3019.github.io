---
title: fupan
date: 2021-10-15 18:29:08
tags:
- 笔试复盘
- 面试复盘
hide: true
categories:
- 复盘
index_img: https://pic2.zhimg.com/v2-5b5bf59a17d6947d72b22b358b6805ca_r.jpg
banner_img: https://pic2.zhimg.com/v2-5b5bf59a17d6947d72b22b358b6805ca_r.jpg

---

# 秋招复盘

## 笔试复盘

### 微众银行

* hive sql和sql的区别

  - hive支持转换后的数据直接写入不同的表，还能写入分区，HDFS和本地目录
  - SQL中null代表空值, 值得警惕的是, 在HiveQL中String类型的字段若是空(empty)字符串, 即长度为0, 那么对它进行IS NULL的判断结果是False.Hive中的Null在底层是以“\N”来存储，而MySQL中的Null在底层就是Null
  -   SQL中对两表内联可以写成：select * from dual a,dual b where a.key = b.key;
      Hive中应为：select * from dual a join dual b on a.key = b.key; 

* 存储过程和函数定义的区别

  - 存储过程是在大型数据库系统中，一组为了完成特定功能的SQL语句集，存储在数据库中，经过第一次编译后再次调用不需要再次编译，用户通过指定存储过程的名字给出参数来调用存储过程。
  - 函数与存储过程类似，也是数据库中存储的已命名PL-SQL程序块。函数的特征是它必须有一个返回值。通过return来指定函数的返回类型。在函数的任何地方可以通过return expression语句从函数返回，返回类型必须和声明的返回类型一致。

* Hadoop的几种集群模式

  - 本地模式。无需任何守护进程，所有的程序都运行在同一个JVM上执行。在独立模式下调试MR程序非常高效方便。所以一般该模式主要是在学习或者开发阶段调试使用 。
  - 伪分布式模式。Hadoop守护进程运行在本地机器上，模拟一个小规模的集群，换句话说，可以配置一台机器的Hadoop集群,伪分布式是完全分布式的一个特例。
  - 完全分布式模式。Hadoop守护进程运行在一个集群上。

* sql中的with,怎么修改表结构

  ````sql
  1.添加字段
  
  　　alter  table  <基本表名>  add  <列名>  <类型>
  
  　　alter  table  s  add  age  varchar(30)
  
  2.删除字段
  
  　　alter  table  <基本表名>  drop  <列名>  [cascade|restrict]
  
  　　alter  table  s  drop  age  cascade
  
  3.修改字段
  
  　　alter  table  <基本表名>  modify  <列名>  <类型>、
  
  　　alter  table  s  modify  age  char(6)
  
  4.索引的创建
  
  　　4-1>唯一索引（asc或desc指定升序或降序的索引值存储）
  
  　　　　create  [unique]  index  <索引名>  on  <基本表名>  (<列名序列>)                //unique  唯一的
  
  　　　　carate  unique  index  s_index  on  s  (sid  asc,cid  desc);
  
  　　4-2>  普通索引
  
  　　　　CREATE INDEX <索引的名字> ON tablename (列的列表)；　
  
   
  
  5.索引的撤消
  
  　　drop  index  <索引名>
  
  　　drop  index  s_index,sc_index           
  　　
  with 语句
  1.使用with子句可以让子查询重用相同的with查询块,通过select调用（with子句只能被select查询块引用），一般在with查询用到多次情况下。在引用的select语句之前定义,同级只能定义with关键字只能使用一次,多个用逗号分割。
  2. with子句的返回结果存到用户的临时表空间中，只做一次查询，反复使用,提高效率
  例子
  with test_with as(select * from A) select * from B where B.id in(select id from test_with)
  ````

* off-heap堆外内存，on-heap堆内存

* 抽象类和接口的区别：

  - 抽象类要被子类继承，接口要被实现
  - 接口只能做方法声明，抽象类中可以做方法声明，也可以做方法实现
  - 接口里定义的变量只能是公共的静态的常量，抽象类中的变量是普通变量

* hdfs 删除文件为什么没有立马释放磁盘空间

  - 有个文件系统垃圾间隔机制，默认设置一天，也就是说删除的文件需要一天才能被删除。可以通过下面参数设置：fs.trash.interval
  - 文件也可以自己手动删掉，找到垃圾文件存储的位置，直接删除就能马上释放磁盘空间了。

## 面试复盘

### 迅雷（数据开发工程师）

* 一面（60min）

* 自我介绍

* 说项目，问项目（问细节，问架构）

  - DWS,DWT层都是建宽表，宽表都是按照主题去建，主题相当于观察问题的角度，对应着维度表

* MapReduce 流程

* hive架构（HQL怎么转化的）

  - 解析器：将SQL字符串转换成抽象语法树AST，对AST进行语法分析，比如表是否存在，字段是否存在，SQL语义是否有误。（解析器会查询去元数据库查看表是否存在）
  - 编译器：将AST编译生成逻辑执行计划。生成MapReduce程序
  - 优化器：对逻辑执行计划进行优。即对生成的MapReduce程序进行优化
  - 执行器：把逻辑计划转化成可运行的物理计划，对于hive来说就是MR/Spark。将任务提交给Yarn，执行过程中还会访问元数据信息。

* Kafka的架构

* Yarn工作机制

* 算法题

  ````
  构建一颗布尔二叉树
  1当一个节点为叶子节点时，它仅可能存储一个布尔表达式('a == b','a != b','a > b','a >= b','a < b','a <= b')
  2当一个节点不为叶子节点时，它仅可能存储'or'或者'and'其中一个数值，表示逻辑表达式中的或与
  3节点遍历方式选择前序遍历
  4输入(5 == 5 && 3 != 4),输出true￼
  
  {
  	"bool":{
  		"and":{
  			"left":{
  				"bool":{
  					"or":{
  						"left":"1 != 1",
  						"right":"2 == 2"
  					}
  				}
  			},
  			"right":"3 = 4"
  		}
  	}
  }
  ````

* 反问

* 总结：会的东西已经有很多了，要注重更多的细节，不要只是死记硬背。要有自己的理解，在面对一些更灵活的没见过的问题才能提炼出自己的方法。项目答的不好，思路还是不清晰，重点加强对项目的理解。

### 袋鼠云（大数据开发）

* 一面25min   10.19
* 自我介绍
* 项目介绍（具体的技术点）
* 写的shell脚本
* 数据仓库某张表的每一层的操作具体流程
* 数据更新的HQL怎么写，具体实现
* 数据错误怎么重新导入。
  - 外部表数据不指定的话存储在/user/hive/warehouse
* 说一说拉链表
* 印象最深的课程，未来的规划



* 二面（20min）   10.29

* 自我介绍

* 学习路线

* flume的一个配置

* namenode压力太大怎么处理
  - 不知道怎么说，就说了增大内存
  
  - 联邦机制 Federation (元数据切片)    多NN，分别管理不同的元数据
  
    - 为了水平扩展名称服务，Federation使用多组独立的Namenodes/Namespaces。所有的Namenodes是联邦的，也就是说，他们之间相互独立且不需要互相协调，各自分工，管理自己的区域。Datanode被用作通用的数据块存储设备，每个DataNode要向集群中所有的Namenode注册，且周期性的向所有Namenode发送心跳和块报告，并执行来自所有Namenode的命令。
  
    - 1、由于单组Namenode在大规模集群中存在较大的局限性，Hadoop开源社区提供了Federation的方案，由多组Namenode在一个集群中共同提供服务，每个Namenode拥有一部分Namespace，工作互相独立，互不影响。
  
      2、在Federation中，Datanode被用作通用的数据块存储设备，每个DataNode要向集群中所有的Namenode注册，且周期性的向所有Namenode发送心跳和块报告，并执行来自所有Namenode的命令。
  
    - Namespace（命名空间）：由目录、文件和块组成，它支持所有命名空间相关的文件操作，如创建、删除、修改，查看所有文件和目录。
  
* 学校里做的项目

* 和同学发生矛盾怎么处理

* 凉凉，都没怎么问技术问题。寄！！！！！

* HR面       10.29         20min   常规问题

### 深演智能

* 一面（30min）10.28 10：15

* 自我介绍

* 比赛介绍（蓝桥杯）

* 介绍毕业设计的设计思路

* flume Taildirsource

* hive 窗口函数 三个排序

* MR过程 重点说shuffle过程

* Kafka exactly once语义

  - At Least once+幂等性

  - Transaction Coordinator，用于管理Produce发送的消息的事务性。
  - 该`Transaction Coordinator`维护`Transaction Log`，该log存于一个内部的Topic内。由于Topic数据具有持久性，因此事务的状态也具有持久性。

* spark shuffle过程

* 反问





* 二面(25min)   10.28  16：30 
* 自我介绍
* 计算机基础
  - 网络的五层模型，都干了什么
  - 网关，路由器，网桥
    - 路由器：连接不同IP子网的设备，负责寻径和转发，工作在OSI的网络层。
    - 网桥：工作在数据链路层，网桥也叫桥接器，是连接两个局域网的一种存储/转发设备，它能将一个大的LAN分割成多个网段，或将两个以上的LAN互联为一个逻辑LAN，使LAN上所有用户都可以访问路由器。
    - 网关：工作在应用层，不同子网间的翻译器，对收到的信息进行重新打包。
  - 进程线程，线程切换，进程间的通信
    - 进程间的通信：文件和记录锁定，管道，信号量，共享内存，套接字
  - Java 锁
* JVM
  - 双亲委派机制 
  - 自定义类加载器
* Scala  伴生对象
  - object Test ,从语法的角度来讲，上面的语法表示声明了一个伴生对象，但是还是会生成一个伴生类。Scala是纯面向对象的，去除了Java中的static关键字，通过伴生对象模拟static效果。伴生对象是伴随类产生的一个对象。
  - 对Scala源文件进行编译后，默认产生两个字节码文件，一个是伴生类另一个是伴生对象所属类。真正的伴生对象是伴生对象所属类中创建的单例对象。
* HadoopHA
* yarn调度机制
* 建模理论
  - 维度建模，星型模型，雪花模型区别，优劣。
  - 范式建模
* 拉链表
* 反问

# 社招复盘

## 杭州星辰闪烁

一面（2022-12-19）35min

* 介绍一个自己感觉技术含量高的项目
  - 电商项目，全部流程
  - 重点：数据仓库建模，数据仓库分层，每层的具体事情
  - Hive的架构，Hive的一些常见优化
  - yarn工作流程，HDFS读写流程
  - 窗口函数用过哪些
  - Kafka的原理，ack三种模式，ISR队列
  - 三个排序的区别
  - SQL的一些优化
  - Spark（我没准备好就没问了）

二面（2022-12-19）30min

* jvm(没准备好)
* kafka exactly once语义（里面很多细节，要多多学习掌握）
* MySQL索引
* flink中哪里用到了双亲委派机制
* flink的理解
* 要注意基础，简历上写的都要会，要准备好

总结：面试没有准备好，很多东西没有准备好。调整心态，好好准备，重新出发。

### 

## 上海天正智能

* 问项目干了什么

## 宁波港信息通信公司

一面（40min）

* 自我介绍
* 离职原因
* 问项目
  - 杭州东站
  - 宁波交警
  - 华夏银行
* 主要是问项目
* 反问：
  - 后续工作用数栈做一些开发

二面（40min）

* 自我介绍
* 问项目，杭州东站问的多
* 场景题，设计一个预警程序
* 选择大数据专业的原因
* 后续转向大数据开发，做大数据产品的意愿
* 反问



## 伊欧乐科技

一面(48min)

* 自我介绍
* 电商项目询问
  - 自己学校练手的项目，问数据量，实现情况
* 杭州东站
  - 具体的指标，指标的意义（这一块记不清楚，可以去补一补业务的知识）
  - sql怎么优化的
  - python数据同步脚本
* 华夏银行
  - 介绍基本情况，做的事情
  - 数据校验脚本的思路
* 宁波交警数据大屏项目
  - 数据怎么同步的
  - 数据量大小
* 以前公司做什么业务的
* python使用情况怎么样，爬虫，数据分析学过吗
* 反问：该岗位的工作职责，贵司的业务，对我个人学习方面有没有什么建议
  - 要更深入的了解业务，了解一个指标的来龙去脉，
  - 自己模拟一些大数据开发的场景，接口的开发，数据同步到hive
* 感觉G了



## 云徙科技

一面36 min

* 自我介绍
* 三个项目询问
* 出了几个sql题目
* Java怎么样
* 离职原因
* 反问：岗位的职责，出差情况，二面看情况，要求是现场面，但是可以和HR谈



## 禅游科技

一面35 min

* 自我介绍
* 介绍你最有挑战的项目
* 项目中的挑战点，难点
* 数据去向，介绍一下业务，数据量多大
* 工作的开发流程
* 新技术怎么学的，saprk最新版本的了解过吗？
* 最大优势是什么
* 离职原因
* 反问。团队的技术栈主要是哪些

感觉技术栈不是很匹配。

反思：自己介绍项目还是不够清晰。**项目中难点没有总结好**。注意不要语言不要太拖拉，还是得学习一下Java 后端的一些东西。



## 明源云

一面  55min

* 自我介绍

* java 常用的集合框架

* 排序算法知道那些

  - 快排的时间复杂度，最坏情况的时间复杂度，什么时候会出现
  - 快排和归并排序的区别
  - 冒泡排序的时间复杂度

* hadoop的计算引擎MR，spark有什么区别

* MR，Spark shuffle过程

* spark什么时候会发生shuffle，这个记错了 （说反了）

  - coalesce 一般用于缩减分区，默认不执行shuffle
  - reparation 一般用于扩大分区，默认执行shuffle，底层调用的就是coalesce
  - 窄依赖：父RDD一个分区中的数据，还是交给子RDD的一个分区处理
  - 宽依赖：父RDD一个分区中的数据，交给子RDD的多个分区处理。分区中数据打乱了，进行了shuffle操作

* 关系型数据库用过吗？mysql查询很慢怎么办

  - mysql索引 说一下 （这里又说错了）
  - mysql是b+tree索引  ，二分查找是在有序的数据结构里面查（logn ）的时间复杂度

* 数仓的分层

* SQL调优

  - 我用我制作拉链表的过程去回答了这个问题
  - 从缓慢维度的设计理论，到分区的选择，到编写时遇到的问题，三个层次递进的回答。（但是感觉还是没讲清楚）要再练一下
  - 不动态分区，left semi join

* 对datax的了解，其他的一些数据同步的工具

* 设计工作流时尽量满足高内聚低耦合的设计思想是要怎么做的

* 指标相关的概念，指标体系怎么构建

  - 这里回答的也不太好，数仓理论还得再看

* sql题 这题比较简单

  ````sql
  customers
  	customer_id INT
  	name VARCHAR(100)
  
  orders
  	order_id INT
  	customer_id INT
  	order_date DATE
  	amount DECIMAL(10, 2)
  
  问题：过去一年内没有新订单的所有客户
  with tmp as (select customer_id from orders where order_date>=date_sub(current_date(),365))
  select customer_id from customers left join tmp where tmp.customer_id is null
  ````

* spark比较熟悉吗

* 离职还是在职，离职原因，毕业年限

* 反问：

  - 整个工作内容，工作工具
  - 业务模式
  - 整个的技术栈
  - 对深圳的发展和计划

二面

* 自我介绍

* 袋鼠云主要做的工作

* DTstack和dataworks的区别

* 为什么离开袋鼠云
  - 离职原因我要考虑考虑看看怎么说合适**&&&&**
  
* 最近的一份工作所担任的角色，主要负责的内容是哪些

* 最熟悉的政策域，说一下它主要的一个业务过程

* 数仓用的是什么，计算引擎是什么。数据量的

* 数仓中事实表分为哪几种 **&&&&**
  - 这个答的还是不够好，对事物事实表的理解，周期快照事实表，累积快照事实表的理解不够深入
  
* 事务事实表有没有用过，理解的业务过程是什么？跟事实表是什么关系
  - 这里对问题理解有误，回答的不好。理解成了“事务事实是什么”。这个问题还是值得深入思考的 **&&&&**
  
* 根据数据情况选择增量更新，全量更新，是怎么选择的 **&&&&**
  - 这里答的不好，没怎么准备过。还是要把自己简历上写的东西去理解透彻。
  - 如果是只保留最新的一个数据，具体是怎么做的
  
* 政策域做了几个宽表，怎么做的 

* 聊一下维度表这一块的内容，维度属性是多值的这种情况怎么做的

* 有没有了解其他公司是怎么用来处理这种递归维度结构的数据的
  - 桥接表的方式 **&&&&**
  - 桥接表的方式，多了解一下。那本书真是数仓建设的圣经啊，多读 ，多看，多理解。最好用于实战
  
* 介绍Starrocks怎么引入的，怎么用的

* SR的数据模型有几个，是怎么用的 **&&&&**
  - 主键表和更新表的差异，怎么用的
  - 主键表和明细表的区别
  - 平时怎么用的，业务场景有什么区别
  - 这里也要多看一下
  
* 数据治理主要做了哪些事情

* 你觉得数据治理包括哪些东西  **&&&&**

* 交付的时候都是去面客，有没有一些困难

* 你觉得你在工作中遇到的最大的困难是什么  
  - 可以准备一下这种问题
  
* 最近有学什么新技术吗？怎么学的

* 优点和缺点各说三个

  - 优点：
    - 细心
    - 比较能吃苦
    - 能坚持
  - 缺点
    - 不太自信
    - 容易紧张
    - 沟通习惯不太好

  - 可以准备一下这种问题

* 怎么更好的沟通

* 反问
  - 我这个组，我这个岗位做的业务主要是什么
  - 大数据部门
    - 架构组
      - 大数据平台的维护，大数据组件类的维护
    - 资产组
      - 是资产组的岗位
      - 负责pass平台的维护
        - 也负责部分架构组的内容
        - 界面的维护
        - **所有业务线的数据资产的数仓开发，指标梳理开发**
        - 维护pass平台上层的应用（涉及到一些后台开发，会涉及到一些后端的知识）
        - 数据采集，清洗都是在pass平台做，最后输出给客户
    - 应用组

三面HR

* 自我介绍
* 哪一年毕业的
* 未来的规划
* 两份工作经历的离职原因
  - 袋鼠的离职原因要怎么讲合适
* toG项目技术为什么提升不快
* 对下一份工作经历的期待
* 学习思路是怎么样的
* 对这个岗位的理解
  - 主要做对数据资产的建设
* 你想通过我们这个岗位收获什么
* 你第一份工作经历的业务经历，它的主要业务
* 怎么快速深入业务
* 在袋鼠有遇到什么困难和挑战
* 这个岗位的数据资产组一般对接三个团队
  - 其他业务团队数据调用的需求
  - 数据产品经理的需求
  - 和一线同事的一些沟通
    - 对一些伪问题要进行分辨
  - 怎么和这些同事处理好沟通的问题
* 挑一个你主要负责的项目讲一下 **&&&**
* 这个项目遇到的典型的难题怎么处理**&&**
  - 旧的业务系统的沟通
* 优势和待提升点是什么**&&**
  - 细心，努力，坚持
  - 沟通有待提升
* 前两份工作的薪资和五险一金基数
* 反问：hc空缺的原因
  - 人员离职
* 资产组六个人
  - 数据开发3~4个
  - 2个测试
